{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows:\n",
    "- Install SystemML Python package and jar file\n",
    "  - pip\n",
    "  - SystemML 'Hello World'\n",
    "- Example 1: Matrix Multiplication\n",
    "- Load diabetes dataset from scikit-learn\n",
    "- Example 2: Implement three different algorithms to train linear regression model\n",
    "  - Algorithm 1: Linear Regression - Direct Solve (no regularization)\n",
    "  - Algorithm 2: Linear Regression - Batch Gradient Descent (no regularization)\n",
    "  - Algorithm 3: Linear Regression - Conjugate Gradient (no regularization)\n",
    "- Example 3: Invoke existing SystemML algorithm script LinearRegDS.dml using MLContext API\n",
    "- Example 4: Invoke existing SystemML algorithm using scikit-learn/SparkML pipeline like API\n",
    "- Example 5: Invoking a Keras model with SystemML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install SystemML Python package and jar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user systemml==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://sparktc.ibmcloud.com/repo/latest/systemml-1.2.0-SNAPSHOT-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/apache/systemml.git\n",
      "  Downloading https://github.com/apache/systemml.git\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cannot unpack file C:\\Users\\ming\\AppData\\Local\\Temp\\pip-unpack-5uxml6sa\\systemml.git (downloaded from C:\\Users\\ming\\AppData\\Local\\Temp\\pip-req-build-aql94_kc, content-type: text/html; charset=utf-8); cannot detect archive format\n",
      "Cannot determine archive format of C:\\Users\\ming\\AppData\\Local\\Temp\\pip-req-build-aql94_kc\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/apache/systemml.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(systemml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemml import MLContext, dml, dmlFromResource, dmlFromFile, dmlFromUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import systemml \n",
    "from systemml import mlcontext\n",
    "from systemml.mllearn import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package systemml:\n",
      "\n",
      "NAME\n",
      "    systemml\n",
      "\n",
      "DESCRIPTION\n",
      "    #-------------------------------------------------------------\n",
      "    #\n",
      "    # Licensed to the Apache Software Foundation (ASF) under one\n",
      "    # or more contributor license agreements.  See the NOTICE file\n",
      "    # distributed with this work for additional information\n",
      "    # regarding copyright ownership.  The ASF licenses this file\n",
      "    # to you under the Apache License, Version 2.0 (the\n",
      "    # \"License\"); you may not use this file except in compliance\n",
      "    # with the License.  You may obtain a copy of the License at\n",
      "    #\n",
      "    #   http://www.apache.org/licenses/LICENSE-2.0\n",
      "    #\n",
      "    # Unless required by applicable law or agreed to in writing,\n",
      "    # software distributed under the License is distributed on an\n",
      "    # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
      "    # KIND, either express or implied.  See the License for the\n",
      "    # specific language governing permissions and limitations\n",
      "    # under the License.\n",
      "    #\n",
      "    #-------------------------------------------------------------\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    classloader\n",
      "    converters\n",
      "    defmatrix\n",
      "    mlcontext\n",
      "    mllearn (package)\n",
      "    project_info\n",
      "    random (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        systemml.defmatrix.DMLOp\n",
      "        systemml.defmatrix.matrix\n",
      "        systemml.mlcontext.MLContext\n",
      "        systemml.mlcontext.MLResults\n",
      "        systemml.mlcontext.Matrix\n",
      "        systemml.mlcontext.Script\n",
      "    \n",
      "    class DMLOp(builtins.object)\n",
      "     |  Represents an intermediate node of Abstract syntax tree created to generate the PyDML script\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, inputs, dml=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MAX_DEPTH = 0\n",
      "    \n",
      "    class MLContext(builtins.object)\n",
      "     |  Wrapper around the new SystemML MLContext.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  sc: SparkContext or SparkSession\n",
      "     |      An instance of pyspark.SparkContext or pyspark.sql.SparkSession.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, sc)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  buildTime(self)\n",
      "     |      Display the project build time.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes this MLContext instance to cleanup buffer pool, static/local state and scratch space.\n",
      "     |      Note the SparkContext is not explicitly closed to allow external reuse.\n",
      "     |  \n",
      "     |  execute(self, script)\n",
      "     |      Execute a DML / PyDML script.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      script: Script instance\n",
      "     |          Script instance defined with the appropriate input and output variables.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ml_results: MLResults\n",
      "     |          MLResults instance.\n",
      "     |  \n",
      "     |  info(self)\n",
      "     |      Display the project information.\n",
      "     |  \n",
      "     |  isExplain(self)\n",
      "     |      Returns True if program instruction details should be output, False otherwise.\n",
      "     |  \n",
      "     |  isForceGPU(self)\n",
      "     |      Returns True if \"force\" GPU mode is enabled, False otherwise.\n",
      "     |  \n",
      "     |  isGPU(self)\n",
      "     |      Returns True if GPU mode is enabled, False otherwise.\n",
      "     |  \n",
      "     |  isStatistics(self)\n",
      "     |      Returns True if program execution statistics should be output, False otherwise.\n",
      "     |  \n",
      "     |  resetConfig(self)\n",
      "     |      Reset configuration settings to default values.\n",
      "     |  \n",
      "     |  setConfig(self, configFilePath)\n",
      "     |      Set SystemML configuration based on a configuration file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      configFilePath: String\n",
      "     |  \n",
      "     |  setConfigProperty(self, propertyName, propertyValue)\n",
      "     |      Set configuration property, such as setConfigProperty(\"sysml.localtmpdir\", \"/tmp/systemml\").\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      propertyName: String\n",
      "     |      propertyValue: String\n",
      "     |  \n",
      "     |  setExplain(self, explain)\n",
      "     |      Explanation about the program. Mainly intended for developers.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      explain: boolean\n",
      "     |  \n",
      "     |  setExplainLevel(self, explainLevel)\n",
      "     |      Set explain level.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      explainLevel: string\n",
      "     |          Can be one of \"hops\", \"runtime\", \"recompile_hops\", \"recompile_runtime\"\n",
      "     |          or in the above in upper case.\n",
      "     |  \n",
      "     |  setForceGPU(self, enable)\n",
      "     |      Whether or not to force the usage of GPU operators.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      enable: boolean\n",
      "     |  \n",
      "     |  setGPU(self, enable)\n",
      "     |      Whether or not to enable GPU.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      enable: boolean\n",
      "     |  \n",
      "     |  setStatistics(self, statistics)\n",
      "     |      Whether or not to output statistics (such as execution time, elapsed time)\n",
      "     |      about script executions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      statistics: boolean\n",
      "     |  \n",
      "     |  setStatisticsMaxHeavyHitters(self, maxHeavyHitters)\n",
      "     |      The maximum number of heavy hitters that are printed as part of the statistics.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxHeavyHitters: int\n",
      "     |  \n",
      "     |  version(self)\n",
      "     |      Display the project version.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MLResults(builtins.object)\n",
      "     |  Wrapper around a Java ML Results object.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  results: JavaObject\n",
      "     |      A Java MLResults object as returned by calling `ml.execute()`.\n",
      "     |  \n",
      "     |  sc: SparkContext\n",
      "     |      SparkContext\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, results, sc)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(self, *outputs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      outputs: string, list of strings\n",
      "     |          Output variables as defined inside the DML script.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Matrix(builtins.object)\n",
      "     |  Wrapper around a Java Matrix object.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  javaMatrix: JavaObject\n",
      "     |      A Java Matrix object as returned by calling `ml.execute().get()`.\n",
      "     |  \n",
      "     |  sc: SparkContext\n",
      "     |      SparkContext\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, javaMatrix, sc)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  toDF(self)\n",
      "     |      Convert the Matrix to a PySpark SQL DataFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      PySpark SQL DataFrame\n",
      "     |          A PySpark SQL DataFrame representing the matrix, with\n",
      "     |          one \"__INDEX\" column containing the row index (since Spark\n",
      "     |          DataFrames are unordered), followed by columns of doubles\n",
      "     |          for each column in the matrix.\n",
      "     |  \n",
      "     |  toNumPy(self)\n",
      "     |      Convert the Matrix to a NumPy Array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      NumPy Array\n",
      "     |          A NumPy Array representing the Matrix object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Script(builtins.object)\n",
      "     |  Instance of a DML/PyDML Script.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  scriptString: string\n",
      "     |      Can be either a file path to a DML script or a DML script itself.\n",
      "     |  \n",
      "     |  scriptType: string\n",
      "     |      Script language, either \"dml\" for DML (R-like) or \"pydml\" for PyDML (Python-like).\n",
      "     |  \n",
      "     |  isResource: boolean\n",
      "     |      If true, scriptString is a path to a resource on the classpath\n",
      "     |  \n",
      "     |  scriptFormat: string\n",
      "     |      Optional script format, either \"auto\" or \"url\" or \"file\" or \"resource\" or \"string\"\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, scriptString, scriptType='dml', isResource=False, scriptFormat='auto')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  clearAll(self)\n",
      "     |      Clear the script string, inputs, outputs, and symbol table.\n",
      "     |  \n",
      "     |  clearIO(self)\n",
      "     |      Clear the inputs and outputs, but not the symbol table.\n",
      "     |  \n",
      "     |  clearIOS(self)\n",
      "     |      Clear the inputs, outputs, and symbol table.\n",
      "     |  \n",
      "     |  clearInputs(self)\n",
      "     |      Clear the inputs.\n",
      "     |  \n",
      "     |  clearOutputs(self)\n",
      "     |      Clear the outputs.\n",
      "     |  \n",
      "     |  clearSymbolTable(self)\n",
      "     |      Clear the symbol table.\n",
      "     |  \n",
      "     |  displayInputParameters(self)\n",
      "     |      Display the script input parameters.\n",
      "     |  \n",
      "     |  displayInputVariables(self)\n",
      "     |      Display the script input variables.\n",
      "     |  \n",
      "     |  displayInputs(self)\n",
      "     |      Display the script inputs.\n",
      "     |  \n",
      "     |  displayOutputVariables(self)\n",
      "     |      Display the script output variables.\n",
      "     |  \n",
      "     |  displayOutputs(self)\n",
      "     |      Display the script outputs.\n",
      "     |  \n",
      "     |  displaySymbolTable(self)\n",
      "     |      Display the script symbol table.\n",
      "     |  \n",
      "     |  getInputVariables(self)\n",
      "     |      Obtain the input variable names.\n",
      "     |  \n",
      "     |  getName(self)\n",
      "     |      Obtain the script name.\n",
      "     |  \n",
      "     |  getOutputVariables(self)\n",
      "     |      Obtain the output variable names.\n",
      "     |  \n",
      "     |  getResults(self)\n",
      "     |      Obtain the results of the script execution.\n",
      "     |  \n",
      "     |  getScriptExecutionString(self)\n",
      "     |      Generate the script execution string, which adds read/load/write/save\n",
      "     |      statements to the beginning and end of the script to execute.\n",
      "     |  \n",
      "     |  getScriptString(self)\n",
      "     |      Obtain the script string (in unicode).\n",
      "     |  \n",
      "     |  getScriptType(self)\n",
      "     |      Obtain the script type.\n",
      "     |  \n",
      "     |  info(self)\n",
      "     |      Display information about the script as a String. This consists of the\n",
      "     |      script type, inputs, outputs, input parameters, input variables, output\n",
      "     |      variables, the symbol table, the script string, and the script execution string.\n",
      "     |  \n",
      "     |  input(self, *args, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: name, value tuple\n",
      "     |          where name is a string, and currently supported value formats\n",
      "     |          are double, string, dataframe, rdd, and list of such object.\n",
      "     |      \n",
      "     |      kwargs: dict of name, value pairs\n",
      "     |          To know what formats are supported for name and value, look above.\n",
      "     |  \n",
      "     |  isDML(self)\n",
      "     |      Is the script type DML?\n",
      "     |  \n",
      "     |  isPYDML(self)\n",
      "     |      Is the script type DML?\n",
      "     |  \n",
      "     |  output(self, *names)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      names: string, list of strings\n",
      "     |          Output variables as defined inside the DML script.\n",
      "     |  \n",
      "     |  results(self)\n",
      "     |      Obtain the results of the script execution.\n",
      "     |  \n",
      "     |  setName(self, name)\n",
      "     |      Set the script name.\n",
      "     |  \n",
      "     |  setResults(self, results)\n",
      "     |      Set the results of the script execution.\n",
      "     |  \n",
      "     |  setScriptString(self, scriptString)\n",
      "     |      Set the script string.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      scriptString: string\n",
      "     |          Can be either a file path to a DML script or a DML script itself.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class matrix(builtins.object)\n",
      "     |  matrix class is a python wrapper that implements basic matrix operators, matrix functions\n",
      "     |  as well as converters to common Python types (for example: Numpy arrays, PySpark DataFrame\n",
      "     |  and Pandas DataFrame). \n",
      "     |  \n",
      "     |  The operators supported are:\n",
      "     |  \n",
      "     |  1. Arithmetic operators: +, -, *, /, //, %, ** as well as dot (i.e. matrix multiplication)\n",
      "     |  2. Indexing in the matrix\n",
      "     |  3. Relational/Boolean operators: <, <=, >, >=, ==, !=, &, |\n",
      "     |  \n",
      "     |  In addition, following functions are supported for matrix:\n",
      "     |  \n",
      "     |  1. transpose\n",
      "     |  2. Aggregation functions: sum, mean, var, sd, max, min, argmin, argmax, cumsum\n",
      "     |  3. Global statistical built-In functions: exp, log, abs, sqrt, round, floor, ceil, ceiling, sin, cos, tan, asin, acos, atan, sign, solve\n",
      "     |  \n",
      "     |  For all the above functions, we always return a two dimensional matrix, especially for aggregation functions with axis. \n",
      "     |  For example: Assuming m1 is a matrix of (3, n), NumPy returns a 1d vector of dimension (3,) for operation m1.sum(axis=1)\n",
      "     |  whereas SystemML returns a 2d matrix of dimension (3, 1).\n",
      "     |  \n",
      "     |  Note: an evaluated matrix contains a data field computed by eval method as DataFrame or NumPy array.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import SystemML as sml\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> sml.setSparkContext(sc)\n",
      "     |  \n",
      "     |  Welcome to Apache SystemML!\n",
      "     |  \n",
      "     |  >>> m1 = sml.matrix(np.ones((3,3)) + 2)\n",
      "     |  >>> m2 = sml.matrix(np.ones((3,3)) + 3)\n",
      "     |  >>> m2 = m1 * (m2 + m1)\n",
      "     |  >>> m4 = 1.0 - m2\n",
      "     |  >>> m4\n",
      "     |  # This matrix (mVar5) is backed by below given PyDML script (which is not yet evaluated). To fetch the data of this matrix, invoke toNumPy() or toDF() or toPandas() methods.\n",
      "     |  mVar1 = load(\" \", format=\"csv\")\n",
      "     |  mVar2 = load(\" \", format=\"csv\")\n",
      "     |  mVar3 = mVar2 + mVar1\n",
      "     |  mVar4 = mVar1 * mVar3\n",
      "     |  mVar5 = 1.0 - mVar4\n",
      "     |  save(mVar5, \" \")\n",
      "     |  >>> m2.eval()\n",
      "     |  >>> m2\n",
      "     |  # This matrix (mVar4) is backed by NumPy array. To fetch the NumPy array, invoke toNumPy() method.\n",
      "     |  >>> m4\n",
      "     |  # This matrix (mVar5) is backed by below given PyDML script (which is not yet evaluated). To fetch the data of this matrix, invoke toNumPy() or toDF() or toPandas() methods.\n",
      "     |  mVar4 = load(\" \", format=\"csv\")\n",
      "     |  mVar5 = 1.0 - mVar4\n",
      "     |  save(mVar5, \" \")\n",
      "     |  >>> m4.sum(axis=1).toNumPy()\n",
      "     |  array([[-60.],\n",
      "     |         [-60.],\n",
      "     |         [-60.]])\n",
      "     |  \n",
      "     |  Design Decisions:\n",
      "     |  \n",
      "     |  1. Until eval() method is invoked, we create an AST (not exposed to the user) that consist of unevaluated operations and data required by those operations.\n",
      "     |     As an anology, a spark user can treat eval() method similar to calling RDD.persist() followed by RDD.count().\n",
      "     |  2. The AST consist of two kinds of nodes: either of type matrix or of type DMLOp.\n",
      "     |     Both these classes expose _visit method, that helps in traversing the AST in DFS manner.\n",
      "     |  3. A matrix object can either be evaluated or not.\n",
      "     |     If evaluated, the attribute 'data' is set to one of the supported types (for example: NumPy array or DataFrame). In this case, the attribute 'op' is set to None.\n",
      "     |     If not evaluated, the attribute 'op' which refers to one of the intermediate node of AST and if of type DMLOp.  In this case, the attribute 'data' is set to None.\n",
      "     |  4. DMLOp has an attribute 'inputs' which contains list of matrix objects or DMLOp.\n",
      "     |  5. To simplify the traversal, every matrix object is considered immutable and an matrix operations creates a new matrix object.\n",
      "     |     As an example: \n",
      "     |     `m1 = sml.matrix(np.ones((3,3)))` creates a matrix object backed by 'data=(np.ones((3,3))'.\n",
      "     |     `m1 = m1 * 2` will create a new matrix object which is now backed by 'op=DMLOp( ... )' whose input is earlier created matrix object.\n",
      "     |  6. Left indexing (implemented in __setitem__ method) is a special case, where Python expects the existing object to be mutated.\n",
      "     |     To ensure the above property, we make deep copy of existing object and point any references to the left-indexed matrix to the newly created object.\n",
      "     |     Then the left-indexed matrix is set to be backed by DMLOp consisting of following pydml:\n",
      "     |     left-indexed-matrix = new-deep-copied-matrix\n",
      "     |     left-indexed-matrix[index] = value\n",
      "     |  7. Please use m.print_ast() and/or  type `m` for debugging. Here is a sample session:\n",
      "     |  \n",
      "     |     >>> npm = np.ones((3,3))\n",
      "     |     >>> m1 = sml.matrix(npm + 3)\n",
      "     |     >>> m2 = sml.matrix(npm + 5)\n",
      "     |     >>> m3 = m1 + m2\n",
      "     |     >>> m3\n",
      "     |     mVar2 = load(\" \", format=\"csv\")\n",
      "     |     mVar1 = load(\" \", format=\"csv\")\n",
      "     |     mVar3 = mVar1 + mVar2\n",
      "     |     save(mVar3, \" \")\n",
      "     |     >>> m3.print_ast()\n",
      "     |     - [mVar3] (op).\n",
      "     |       - [mVar1] (data).\n",
      "     |       - [mVar2] (data).\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __and__(self, other)\n",
      "     |      # TODO: Cast the output back into scalar and return boolean results\n",
      "     |  \n",
      "     |  __array__(self, dtype=<class 'numpy.float64'>)\n",
      "     |      As per NumPy from Python,\n",
      "     |      This method is called to obtain an ndarray object when needed. You should always guarantee this returns an actual ndarray object.\n",
      "     |      \n",
      "     |      Using this method, you get back a ndarray object, and subsequent operations on the returned ndarray object will be singlenode.\n",
      "     |  \n",
      "     |  __div__(self, other)\n",
      "     |      Performs division (Python 2 way).\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Implements evaluation of right indexing operations such as m[1,1], m[0:1,], m[:, 0:1]\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, data, op=None)\n",
      "     |      Constructs a lazy matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data: NumPy ndarray, Pandas DataFrame, scipy sparse matrix or PySpark DataFrame. (data cannot be None for external users, 'data=None' is used internally for lazy evaluation).\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(self, other)\n",
      "     |      Performs matrix multiplication (infix operator: @). See PEP 465)\n",
      "     |  \n",
      "     |  __mod__(self, other)\n",
      "     |  \n",
      "     |  __mul__(self, other)\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __numpy_ufunc__(self, func, method, pos, inputs, **kwargs)\n",
      "     |      This function enables systemml matrix to be compatible with NumPy's ufuncs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func:  ufunc object that was called.\n",
      "     |      method: string indicating which Ufunc method was called (one of \"__call__\", \"reduce\", \"reduceat\", \"accumulate\", \"outer\", \"inner\").\n",
      "     |      pos: index of self in inputs.\n",
      "     |      inputs:  tuple of the input arguments to the ufunc\n",
      "     |      kwargs: dictionary containing the optional input arguments of the ufunc.\n",
      "     |  \n",
      "     |  __or__(self, other)\n",
      "     |  \n",
      "     |  __pow__(self, other)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      This function helps to debug matrix class and also examine the generated PyDML script\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmod__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(self, other)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__(self, other)\n",
      "     |      Performs division (Python 3 way).\n",
      "     |  \n",
      "     |  __setitem__(self, index, value)\n",
      "     |      Implements evaluation of left indexing operations such as m[1,1]=2\n",
      "     |  \n",
      "     |  __sub__(self, other)\n",
      "     |  \n",
      "     |  __truediv__(self, other)\n",
      "     |      Performs division (Python 3 way).\n",
      "     |  \n",
      "     |  abs(self)\n",
      "     |  \n",
      "     |  acos(self)\n",
      "     |  \n",
      "     |  arccos(self)\n",
      "     |  \n",
      "     |  arcsin(self)\n",
      "     |  \n",
      "     |  arctan(self)\n",
      "     |  \n",
      "     |  argmax(self, axis=None)\n",
      "     |      Returns the indices of the maximum values along an axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional (only axis=1, i.e. rowIndexMax is supported in this version)\n",
      "     |  \n",
      "     |  argmin(self, axis=None)\n",
      "     |      Returns the indices of the minimum values along an axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional  (only axis=1, i.e. rowIndexMax is supported in this version)\n",
      "     |  \n",
      "     |  asfptype(self)\n",
      "     |  \n",
      "     |  asin(self)\n",
      "     |  \n",
      "     |  astype(self, t)\n",
      "     |  \n",
      "     |  atan(self)\n",
      "     |  \n",
      "     |  ceil(self)\n",
      "     |  \n",
      "     |  ceiling(self)\n",
      "     |  \n",
      "     |  cos(self)\n",
      "     |  \n",
      "     |  cosh(self)\n",
      "     |  \n",
      "     |  cumsum(self, axis=None)\n",
      "     |      Returns the indices of the maximum values along an axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional (only axis=0, i.e. cumsum along the rows is supported in this version)\n",
      "     |  \n",
      "     |  deg2rad(self)\n",
      "     |      Convert angles from degrees to radians.\n",
      "     |  \n",
      "     |  dot(self, other)\n",
      "     |      Numpy way of performing matrix multiplication\n",
      "     |  \n",
      "     |  eval(self)\n",
      "     |      This is a convenience function that calls the global eval method\n",
      "     |  \n",
      "     |  exp(self)\n",
      "     |  \n",
      "     |  exp2(self)\n",
      "     |  \n",
      "     |  expm1(self)\n",
      "     |  \n",
      "     |  floor(self)\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |  \n",
      "     |  hstack(self, other)\n",
      "     |      Stack matrices horizontally (column wise). Invokes cbind internally.\n",
      "     |  \n",
      "     |  ldexp(self, other)\n",
      "     |  \n",
      "     |  log(self, y=None)\n",
      "     |  \n",
      "     |  log10(self)\n",
      "     |  \n",
      "     |  log1p(self)\n",
      "     |  \n",
      "     |  log2(self)\n",
      "     |  \n",
      "     |  logaddexp(self, other)\n",
      "     |  \n",
      "     |  logaddexp2(self, other)\n",
      "     |  \n",
      "     |  logical_not(self)\n",
      "     |  \n",
      "     |  max(self, other=None, axis=None)\n",
      "     |      Compute the maximum value along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other: matrix or numpy array (& other supported types) or scalar\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  mean(self, axis=None)\n",
      "     |      Compute the arithmetic mean along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  min(self, other=None, axis=None)\n",
      "     |      Compute the minimum value along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other: matrix or numpy array (& other supported types) or scalar\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  mod(self, other)\n",
      "     |  \n",
      "     |  moment(self, moment=1, axis=None)\n",
      "     |      Calculates the nth moment about the mean\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      moment : int\n",
      "     |          can be 1, 2, 3 or 4\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  negative(self)\n",
      "     |  \n",
      "     |  ones_like(self)\n",
      "     |  \n",
      "     |  print_ast(self)\n",
      "     |      Please use m.print_ast() and/or  type `m` for debugging. Here is a sample session:\n",
      "     |      \n",
      "     |      >>> npm = np.ones((3,3))\n",
      "     |      >>> m1 = sml.matrix(npm + 3)\n",
      "     |      >>> m2 = sml.matrix(npm + 5)\n",
      "     |      >>> m3 = m1 + m2\n",
      "     |      >>> m3\n",
      "     |      mVar2 = load(\" \", format=\"csv\")\n",
      "     |      mVar1 = load(\" \", format=\"csv\")\n",
      "     |      mVar3 = mVar1 + mVar2\n",
      "     |      save(mVar3, \" \")\n",
      "     |      >>> m3.print_ast()\n",
      "     |      - [mVar3] (op).\n",
      "     |        - [mVar1] (data).\n",
      "     |        - [mVar2] (data).\n",
      "     |  \n",
      "     |  prod(self)\n",
      "     |      Return the product of all cells in matrix\n",
      "     |  \n",
      "     |  rad2deg(self)\n",
      "     |      Convert angles from radians to degrees.\n",
      "     |  \n",
      "     |  reciprocal(self)\n",
      "     |  \n",
      "     |  remainder(self, other)\n",
      "     |  \n",
      "     |  remove_empty(self, axis=None)\n",
      "     |      Removes all empty rows or columns from the input matrix target X according to specified axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int (0 or 1)\n",
      "     |  \n",
      "     |  replace(self, pattern=None, replacement=None)\n",
      "     |      Removes all empty rows or columns from the input matrix target X according to specified axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pattern : float or int\n",
      "     |      replacement : float or int\n",
      "     |  \n",
      "     |  round(self)\n",
      "     |  \n",
      "     |  save(self, file, format='csv')\n",
      "     |      Allows user to save a matrix to filesystem\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      file: filepath\n",
      "     |      format: can be csv, text or binary or mm\n",
      "     |  \n",
      "     |  sd(self, axis=None)\n",
      "     |      Compute the standard deviation along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |  \n",
      "     |  sign(self)\n",
      "     |  \n",
      "     |  sin(self)\n",
      "     |  \n",
      "     |  sinh(self)\n",
      "     |  \n",
      "     |  sqrt(self)\n",
      "     |  \n",
      "     |  square(self)\n",
      "     |  \n",
      "     |  sum(self, axis=None)\n",
      "     |      Compute the sum along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  tan(self)\n",
      "     |  \n",
      "     |  tanh(self)\n",
      "     |  \n",
      "     |  toDF(self)\n",
      "     |      This is a convenience function that calls the global eval method and then converts the matrix object into DataFrame.\n",
      "     |  \n",
      "     |  toNumPy(self)\n",
      "     |      This is a convenience function that calls the global eval method and then converts the matrix object into NumPy array.\n",
      "     |  \n",
      "     |  toPandas(self)\n",
      "     |      This is a convenience function that calls the global eval method and then converts the matrix object into Pandas DataFrame.\n",
      "     |  \n",
      "     |  trace(self)\n",
      "     |      Return the sum of the cells of the main diagonal square matrix\n",
      "     |  \n",
      "     |  transpose(self)\n",
      "     |      Transposes the matrix.\n",
      "     |  \n",
      "     |  var(self, axis=None)\n",
      "     |      Compute the variance along the specified axis.\n",
      "     |      We assume that delta degree of freedom is 1 (unlike NumPy which assumes ddof=0).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  vstack(self, other)\n",
      "     |      Stack matrices vertically (row wise). Invokes rbind internally.\n",
      "     |  \n",
      "     |  zeros_like(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  THROW_ARRAY_CONVERSION_ERROR = False\n",
      "     |  \n",
      "     |  __array_priority__ = 10.2\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  dml = []\n",
      "     |  \n",
      "     |  ml = None\n",
      "     |  \n",
      "     |  ndim = 2\n",
      "     |  \n",
      "     |  script = None\n",
      "     |  \n",
      "     |  systemmlVarID = 0\n",
      "     |  \n",
      "     |  visited = []\n",
      "\n",
      "FUNCTIONS\n",
      "    _java2py(sc, obj)\n",
      "        Convert Java object to Python.\n",
      "    \n",
      "    convertImageToNumPyArr(im, img_shape=None, add_rotated_images=False, add_mirrored_images=False, color_mode='RGB', mean=None)\n",
      "        # Example usage: convertImageToNumPyArr(im, img_shape=(3, 224, 224), add_rotated_images=True, add_mirrored_images=True)\n",
      "        # The above call returns a numpy array of shape (6, 50176) in NCHW format\n",
      "    \n",
      "    convertToLabeledDF(sparkSession, X, y=None)\n",
      "    \n",
      "    convertToMatrixBlock(sc, src, maxSizeBlockInMB=8)\n",
      "    \n",
      "    convertToNumPyArr(sc, mb)\n",
      "    \n",
      "    convertToPandasDF(X)\n",
      "    \n",
      "    convert_caffemodel(sc, deploy_file, caffemodel_file, output_dir, format='binary', is_caffe_installed=False)\n",
      "        Saves the weights and bias in the caffemodel file to output_dir in the specified format.\n",
      "        This method does not requires caffe to be installed.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sc: SparkContext\n",
      "            SparkContext\n",
      "        \n",
      "        deploy_file: string\n",
      "            Path to the input network file\n",
      "        \n",
      "        caffemodel_file: string\n",
      "            Path to the input caffemodel file\n",
      "        \n",
      "        output_dir: string\n",
      "            Path to the output directory\n",
      "        \n",
      "        format: string\n",
      "            Format of the weights and bias (can be binary, csv or text)\n",
      "        \n",
      "        is_caffe_installed: bool\n",
      "            True if caffe is installed\n",
      "    \n",
      "    convert_lmdb_to_jpeg(lmdb_img_file, output_dir)\n",
      "        Saves the images in the lmdb file as jpeg in the output_dir. This method requires caffe to be installed along with lmdb and cv2 package.\n",
      "        To install cv2 package, do `pip install opencv-python`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        lmdb_img_file: string\n",
      "            Path to the input lmdb file\n",
      "        \n",
      "        output_dir: string\n",
      "            Output directory for images (local filesystem)\n",
      "    \n",
      "    debug_array_conversion(throwError)\n",
      "    \n",
      "    dml(scriptString)\n",
      "        Create a dml script object based on a string.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scriptString: string\n",
      "            Can be a path to a dml script or a dml script itself.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    dmlFromFile(filePath)\n",
      "        Create a dml script object based on a file path.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filePath: string\n",
      "            Path to a dml script.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    dmlFromResource(resourcePath)\n",
      "        Create a dml script object based on a resource path.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        resourcePath: string\n",
      "            Path to a dml script on the classpath.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    dmlFromUrl(url)\n",
      "        Create a dml script object based on a url.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        url: string\n",
      "            URL to a dml script.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    eval(outputs, execute=True)\n",
      "        Executes the unevaluated DML script and computes the matrices specified by outputs.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        outputs: list of matrices or a matrix object\n",
      "        execute: specified whether to execute the unevaluated operation or just return the script.\n",
      "    \n",
      "    full(shape, fill_value)\n",
      "        Return a new array of given shape filled with fill_value.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape: tuple of length 2\n",
      "        fill_value: float or int\n",
      "    \n",
      "    getDatasetMean(dataset_name)\n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset_name: Name of the dataset used to train model. This name is artificial name based on dataset used to train the model.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mean: Mean value of model if its defined in the list DATASET_MEAN else None.\n",
      "    \n",
      "    getHopDAG(ml, script, lines=None, conf=None, apply_rewrites=True, with_subgraph=False)\n",
      "        Compile a DML / PyDML script.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ml: MLContext instance\n",
      "            MLContext instance.\n",
      "            \n",
      "        script: Script instance\n",
      "            Script instance defined with the appropriate input and output variables.\n",
      "        \n",
      "        lines: list of integers\n",
      "            Optional: only display the hops that have begin and end line number equals to the given integers.\n",
      "        \n",
      "        conf: SparkConf instance\n",
      "            Optional spark configuration\n",
      "            \n",
      "        apply_rewrites: boolean\n",
      "            If True, perform static rewrites, perform intra-/inter-procedural analysis to propagate size information into functions and apply dynamic rewrites\n",
      "        \n",
      "        with_subgraph: boolean\n",
      "            If False, the dot graph will be created without subgraphs for statement blocks. \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        hopDAG: string\n",
      "            hop DAG in dot format\n",
      "    \n",
      "    getNumCols(numPyArr)\n",
      "    \n",
      "    load(file, format='csv')\n",
      "        Allows user to load a matrix from filesystem\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        file: filepath\n",
      "        format: can be csv, text or binary or mm\n",
      "    \n",
      "    pydml(scriptString)\n",
      "        Create a pydml script object based on a string.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scriptString: string\n",
      "            Can be a path to a pydml script or a pydml script itself.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    pydmlFromFile(filePath)\n",
      "        Create a pydml script object based on a file path.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filePath: string\n",
      "            Path to a pydml script.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    pydmlFromResource(resourcePath)\n",
      "        Create a pydml script object based on a resource path.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        resourcePath: string\n",
      "            Path to a pydml script on the classpath.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    pydmlFromUrl(url)\n",
      "        Create a pydml script object based on a url.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        url: string\n",
      "            URL to a pydml script.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    seq(start=None, stop=None, step=1)\n",
      "        Creates a single column vector with values starting from <start>, to <stop>, in increments of <step>.\n",
      "        Note: Unlike Numpy's arange which returns a row-vector, this returns a column vector.\n",
      "        Also, Unlike Numpy's arange which doesnot include stop, this method includes stop in the interval.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        start: int or float [Optional: default = 0]\n",
      "        stop: int or float\n",
      "        step : int float [Optional: default = 1]\n",
      "    \n",
      "    setSparkContext(sc)\n",
      "        Before using the matrix, the user needs to invoke this function if SparkContext is not previously created in the session.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sc: SparkContext\n",
      "            SparkContext\n",
      "    \n",
      "    set_lazy(isLazy)\n",
      "        This method allows users to set whether the matrix operations should be executed in lazy manner.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        isLazy: True if matrix operations should be evaluated in lazy manner.\n",
      "    \n",
      "    solve(A, b)\n",
      "        Computes the least squares solution for system of linear equations A %*% x = b\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn import datasets\n",
      "        >>> import SystemML as sml\n",
      "        >>> from pyspark.sql import SparkSession\n",
      "        >>> diabetes = datasets.load_diabetes()\n",
      "        >>> diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
      "        >>> X_train = diabetes_X[:-20]\n",
      "        >>> X_test = diabetes_X[-20:]\n",
      "        >>> y_train = diabetes.target[:-20]\n",
      "        >>> y_test = diabetes.target[-20:]\n",
      "        >>> sml.setSparkContext(sc)\n",
      "        >>> X = sml.matrix(X_train)\n",
      "        >>> y = sml.matrix(y_train)\n",
      "        >>> A = X.transpose().dot(X)\n",
      "        >>> b = X.transpose().dot(y)\n",
      "        >>> beta = sml.solve(A, b).toNumPy()\n",
      "        >>> y_predicted = X_test.dot(beta)\n",
      "        >>> print('Residual sum of squares: %.2f' % np.mean((y_predicted - y_test) ** 2))\n",
      "        Residual sum of squares: 25282.12\n",
      "\n",
      "DATA\n",
      "    SUPPORTED_TYPES = (<class 'numpy.ndarray'>, <class 'pandas.core.frame....\n",
      "    __all__ = ['MLResults', 'MLContext', 'Script', 'Matrix', 'dml', 'pydml...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\ming\\appdata\\roaming\\python\\python36\\site-packages\\systemml\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(systemml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemml import classloader\n",
    "from systemml import converters\n",
    "from systemml import defmatrix \n",
    "from systemml import mlcontext\n",
    "from systemml import project_info\n",
    "from systemml import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '__main__.keras2caffe'; '__main__' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-84e25a3e4667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mkeras2caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '__main__.keras2caffe'; '__main__' is not a package"
     ]
    }
   ],
   "source": [
    "from .keras2caffe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ming\\\\Documents\\\\Backup_G\\\\Advanced_Data_Science_with_IBM\\\\coursera\\\\coursera_ai\\\\week2\\\\systemml'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 123] The filename, directory name, or volume label syntax is incorrect: \"'C:\\\\\\\\Users\\\\\\\\ming\\\\\\\\Documents\\\\\\\\Backup_G\\\\\\\\Advanced_Data_Science_with_IBM\\\\\\\\systemml'\"\n",
      "C:\\Users\\ming\\Documents\\Backup_G\\Advanced_Data_Science_with_IBM\\coursera\\coursera_ai\\week2\\systemml\n"
     ]
    }
   ],
   "source": [
    "cd 'C:\\\\Users\\\\ming\\\\Documents\\\\Backup_G\\\\Advanced_Data_Science_with_IBM\\\\systemml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-0ebe8ee82c9d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-0ebe8ee82c9d>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    mvn package -P distributio\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mvn package -P distributio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "import * only allowed at module level (estimators.py, line 917)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\ming\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3291\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-13-8c2f345dce22>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from systemml import mllearn\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ming\\AppData\\Roaming\\Python\\Python36\\site-packages\\systemml\\mllearn\\__init__.py\"\u001b[1;36m, line \u001b[1;32m45\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from .estimators import *\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ming\\AppData\\Roaming\\Python\\Python36\\site-packages\\systemml\\mllearn\\estimators.py\"\u001b[1;36m, line \u001b[1;32m917\u001b[0m\n\u001b[1;33m    def __init__(self, sparkSession, keras_model, input_shape, transferUsingDF=False, load_keras_weights=True, weights=None, labels=None, batch_size=64, max_iter=2000, test_iter=10, test_interval=500, display=100, lr_policy=\"step\", weight_decay=5e-4, regularization_type=\"L2\"):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m import * only allowed at module level\n"
     ]
    }
   ],
   "source": [
    "from systemml import mllearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'systemml' has no attribute 'mllearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c908c8477aca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msystemml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmllearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'systemml' has no attribute 'mllearn'"
     ]
    }
   ],
   "source": [
    "from systemml.mllearn import c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade systemml\n",
    "!pip install --upgrade https://github.com/niketanpansare/future_of_data/raw/master/systemml-1.1.0-SNAPSHOT-python.tar.gz\n",
    "!ln -s -f ~/.local/lib/python2.7/site-packages/systemml/systemml-java/*.jar ~/data/libs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: systemml\n",
      "Version: 1.2.0\n",
      "Summary: Apache SystemML is a distributed and declarative machine learning platform.\n",
      "Home-page: http://systemml.apache.org/\n",
      "Author: Apache SystemML\n",
      "Author-email: dev@systemml.apache.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\ming\\appdata\\roaming\\python\\python36\\site-packages\n",
      "Requires: scipy, Pillow, scikit-learn, numpy, pandas\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show systemml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package systemml:\n",
      "\n",
      "NAME\n",
      "    systemml\n",
      "\n",
      "DESCRIPTION\n",
      "    #-------------------------------------------------------------\n",
      "    #\n",
      "    # Licensed to the Apache Software Foundation (ASF) under one\n",
      "    # or more contributor license agreements.  See the NOTICE file\n",
      "    # distributed with this work for additional information\n",
      "    # regarding copyright ownership.  The ASF licenses this file\n",
      "    # to you under the Apache License, Version 2.0 (the\n",
      "    # \"License\"); you may not use this file except in compliance\n",
      "    # with the License.  You may obtain a copy of the License at\n",
      "    #\n",
      "    #   http://www.apache.org/licenses/LICENSE-2.0\n",
      "    #\n",
      "    # Unless required by applicable law or agreed to in writing,\n",
      "    # software distributed under the License is distributed on an\n",
      "    # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
      "    # KIND, either express or implied.  See the License for the\n",
      "    # specific language governing permissions and limitations\n",
      "    # under the License.\n",
      "    #\n",
      "    #-------------------------------------------------------------\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    classloader\n",
      "    converters\n",
      "    defmatrix\n",
      "    mlcontext\n",
      "    mllearn (package)\n",
      "    project_info\n",
      "    random (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        systemml.defmatrix.DMLOp\n",
      "        systemml.defmatrix.matrix\n",
      "        systemml.mlcontext.MLContext\n",
      "        systemml.mlcontext.MLResults\n",
      "        systemml.mlcontext.Matrix\n",
      "        systemml.mlcontext.Script\n",
      "    \n",
      "    class DMLOp(builtins.object)\n",
      "     |  Represents an intermediate node of Abstract syntax tree created to generate the PyDML script\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, inputs, dml=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MAX_DEPTH = 0\n",
      "    \n",
      "    class MLContext(builtins.object)\n",
      "     |  Wrapper around the new SystemML MLContext.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  sc: SparkContext or SparkSession\n",
      "     |      An instance of pyspark.SparkContext or pyspark.sql.SparkSession.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, sc)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  buildTime(self)\n",
      "     |      Display the project build time.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes this MLContext instance to cleanup buffer pool, static/local state and scratch space.\n",
      "     |      Note the SparkContext is not explicitly closed to allow external reuse.\n",
      "     |  \n",
      "     |  execute(self, script)\n",
      "     |      Execute a DML / PyDML script.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      script: Script instance\n",
      "     |          Script instance defined with the appropriate input and output variables.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      ml_results: MLResults\n",
      "     |          MLResults instance.\n",
      "     |  \n",
      "     |  info(self)\n",
      "     |      Display the project information.\n",
      "     |  \n",
      "     |  isExplain(self)\n",
      "     |      Returns True if program instruction details should be output, False otherwise.\n",
      "     |  \n",
      "     |  isForceGPU(self)\n",
      "     |      Returns True if \"force\" GPU mode is enabled, False otherwise.\n",
      "     |  \n",
      "     |  isGPU(self)\n",
      "     |      Returns True if GPU mode is enabled, False otherwise.\n",
      "     |  \n",
      "     |  isStatistics(self)\n",
      "     |      Returns True if program execution statistics should be output, False otherwise.\n",
      "     |  \n",
      "     |  resetConfig(self)\n",
      "     |      Reset configuration settings to default values.\n",
      "     |  \n",
      "     |  setConfig(self, configFilePath)\n",
      "     |      Set SystemML configuration based on a configuration file.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      configFilePath: String\n",
      "     |  \n",
      "     |  setConfigProperty(self, propertyName, propertyValue)\n",
      "     |      Set configuration property, such as setConfigProperty(\"sysml.localtmpdir\", \"/tmp/systemml\").\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      propertyName: String\n",
      "     |      propertyValue: String\n",
      "     |  \n",
      "     |  setExplain(self, explain)\n",
      "     |      Explanation about the program. Mainly intended for developers.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      explain: boolean\n",
      "     |  \n",
      "     |  setExplainLevel(self, explainLevel)\n",
      "     |      Set explain level.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      explainLevel: string\n",
      "     |          Can be one of \"hops\", \"runtime\", \"recompile_hops\", \"recompile_runtime\"\n",
      "     |          or in the above in upper case.\n",
      "     |  \n",
      "     |  setForceGPU(self, enable)\n",
      "     |      Whether or not to force the usage of GPU operators.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      enable: boolean\n",
      "     |  \n",
      "     |  setGPU(self, enable)\n",
      "     |      Whether or not to enable GPU.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      enable: boolean\n",
      "     |  \n",
      "     |  setStatistics(self, statistics)\n",
      "     |      Whether or not to output statistics (such as execution time, elapsed time)\n",
      "     |      about script executions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      statistics: boolean\n",
      "     |  \n",
      "     |  setStatisticsMaxHeavyHitters(self, maxHeavyHitters)\n",
      "     |      The maximum number of heavy hitters that are printed as part of the statistics.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      maxHeavyHitters: int\n",
      "     |  \n",
      "     |  version(self)\n",
      "     |      Display the project version.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MLResults(builtins.object)\n",
      "     |  Wrapper around a Java ML Results object.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  results: JavaObject\n",
      "     |      A Java MLResults object as returned by calling `ml.execute()`.\n",
      "     |  \n",
      "     |  sc: SparkContext\n",
      "     |      SparkContext\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, results, sc)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get(self, *outputs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      outputs: string, list of strings\n",
      "     |          Output variables as defined inside the DML script.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Matrix(builtins.object)\n",
      "     |  Wrapper around a Java Matrix object.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  javaMatrix: JavaObject\n",
      "     |      A Java Matrix object as returned by calling `ml.execute().get()`.\n",
      "     |  \n",
      "     |  sc: SparkContext\n",
      "     |      SparkContext\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, javaMatrix, sc)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  toDF(self)\n",
      "     |      Convert the Matrix to a PySpark SQL DataFrame.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      PySpark SQL DataFrame\n",
      "     |          A PySpark SQL DataFrame representing the matrix, with\n",
      "     |          one \"__INDEX\" column containing the row index (since Spark\n",
      "     |          DataFrames are unordered), followed by columns of doubles\n",
      "     |          for each column in the matrix.\n",
      "     |  \n",
      "     |  toNumPy(self)\n",
      "     |      Convert the Matrix to a NumPy Array.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      NumPy Array\n",
      "     |          A NumPy Array representing the Matrix object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Script(builtins.object)\n",
      "     |  Instance of a DML/PyDML Script.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  scriptString: string\n",
      "     |      Can be either a file path to a DML script or a DML script itself.\n",
      "     |  \n",
      "     |  scriptType: string\n",
      "     |      Script language, either \"dml\" for DML (R-like) or \"pydml\" for PyDML (Python-like).\n",
      "     |  \n",
      "     |  isResource: boolean\n",
      "     |      If true, scriptString is a path to a resource on the classpath\n",
      "     |  \n",
      "     |  scriptFormat: string\n",
      "     |      Optional script format, either \"auto\" or \"url\" or \"file\" or \"resource\" or \"string\"\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, scriptString, scriptType='dml', isResource=False, scriptFormat='auto')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  clearAll(self)\n",
      "     |      Clear the script string, inputs, outputs, and symbol table.\n",
      "     |  \n",
      "     |  clearIO(self)\n",
      "     |      Clear the inputs and outputs, but not the symbol table.\n",
      "     |  \n",
      "     |  clearIOS(self)\n",
      "     |      Clear the inputs, outputs, and symbol table.\n",
      "     |  \n",
      "     |  clearInputs(self)\n",
      "     |      Clear the inputs.\n",
      "     |  \n",
      "     |  clearOutputs(self)\n",
      "     |      Clear the outputs.\n",
      "     |  \n",
      "     |  clearSymbolTable(self)\n",
      "     |      Clear the symbol table.\n",
      "     |  \n",
      "     |  displayInputParameters(self)\n",
      "     |      Display the script input parameters.\n",
      "     |  \n",
      "     |  displayInputVariables(self)\n",
      "     |      Display the script input variables.\n",
      "     |  \n",
      "     |  displayInputs(self)\n",
      "     |      Display the script inputs.\n",
      "     |  \n",
      "     |  displayOutputVariables(self)\n",
      "     |      Display the script output variables.\n",
      "     |  \n",
      "     |  displayOutputs(self)\n",
      "     |      Display the script outputs.\n",
      "     |  \n",
      "     |  displaySymbolTable(self)\n",
      "     |      Display the script symbol table.\n",
      "     |  \n",
      "     |  getInputVariables(self)\n",
      "     |      Obtain the input variable names.\n",
      "     |  \n",
      "     |  getName(self)\n",
      "     |      Obtain the script name.\n",
      "     |  \n",
      "     |  getOutputVariables(self)\n",
      "     |      Obtain the output variable names.\n",
      "     |  \n",
      "     |  getResults(self)\n",
      "     |      Obtain the results of the script execution.\n",
      "     |  \n",
      "     |  getScriptExecutionString(self)\n",
      "     |      Generate the script execution string, which adds read/load/write/save\n",
      "     |      statements to the beginning and end of the script to execute.\n",
      "     |  \n",
      "     |  getScriptString(self)\n",
      "     |      Obtain the script string (in unicode).\n",
      "     |  \n",
      "     |  getScriptType(self)\n",
      "     |      Obtain the script type.\n",
      "     |  \n",
      "     |  info(self)\n",
      "     |      Display information about the script as a String. This consists of the\n",
      "     |      script type, inputs, outputs, input parameters, input variables, output\n",
      "     |      variables, the symbol table, the script string, and the script execution string.\n",
      "     |  \n",
      "     |  input(self, *args, **kwargs)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      args: name, value tuple\n",
      "     |          where name is a string, and currently supported value formats\n",
      "     |          are double, string, dataframe, rdd, and list of such object.\n",
      "     |      \n",
      "     |      kwargs: dict of name, value pairs\n",
      "     |          To know what formats are supported for name and value, look above.\n",
      "     |  \n",
      "     |  isDML(self)\n",
      "     |      Is the script type DML?\n",
      "     |  \n",
      "     |  isPYDML(self)\n",
      "     |      Is the script type DML?\n",
      "     |  \n",
      "     |  output(self, *names)\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      names: string, list of strings\n",
      "     |          Output variables as defined inside the DML script.\n",
      "     |  \n",
      "     |  results(self)\n",
      "     |      Obtain the results of the script execution.\n",
      "     |  \n",
      "     |  setName(self, name)\n",
      "     |      Set the script name.\n",
      "     |  \n",
      "     |  setResults(self, results)\n",
      "     |      Set the results of the script execution.\n",
      "     |  \n",
      "     |  setScriptString(self, scriptString)\n",
      "     |      Set the script string.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      scriptString: string\n",
      "     |          Can be either a file path to a DML script or a DML script itself.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class matrix(builtins.object)\n",
      "     |  matrix class is a python wrapper that implements basic matrix operators, matrix functions\n",
      "     |  as well as converters to common Python types (for example: Numpy arrays, PySpark DataFrame\n",
      "     |  and Pandas DataFrame). \n",
      "     |  \n",
      "     |  The operators supported are:\n",
      "     |  \n",
      "     |  1. Arithmetic operators: +, -, *, /, //, %, ** as well as dot (i.e. matrix multiplication)\n",
      "     |  2. Indexing in the matrix\n",
      "     |  3. Relational/Boolean operators: <, <=, >, >=, ==, !=, &, |\n",
      "     |  \n",
      "     |  In addition, following functions are supported for matrix:\n",
      "     |  \n",
      "     |  1. transpose\n",
      "     |  2. Aggregation functions: sum, mean, var, sd, max, min, argmin, argmax, cumsum\n",
      "     |  3. Global statistical built-In functions: exp, log, abs, sqrt, round, floor, ceil, ceiling, sin, cos, tan, asin, acos, atan, sign, solve\n",
      "     |  \n",
      "     |  For all the above functions, we always return a two dimensional matrix, especially for aggregation functions with axis. \n",
      "     |  For example: Assuming m1 is a matrix of (3, n), NumPy returns a 1d vector of dimension (3,) for operation m1.sum(axis=1)\n",
      "     |  whereas SystemML returns a 2d matrix of dimension (3, 1).\n",
      "     |  \n",
      "     |  Note: an evaluated matrix contains a data field computed by eval method as DataFrame or NumPy array.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import SystemML as sml\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> sml.setSparkContext(sc)\n",
      "     |  \n",
      "     |  Welcome to Apache SystemML!\n",
      "     |  \n",
      "     |  >>> m1 = sml.matrix(np.ones((3,3)) + 2)\n",
      "     |  >>> m2 = sml.matrix(np.ones((3,3)) + 3)\n",
      "     |  >>> m2 = m1 * (m2 + m1)\n",
      "     |  >>> m4 = 1.0 - m2\n",
      "     |  >>> m4\n",
      "     |  # This matrix (mVar5) is backed by below given PyDML script (which is not yet evaluated). To fetch the data of this matrix, invoke toNumPy() or toDF() or toPandas() methods.\n",
      "     |  mVar1 = load(\" \", format=\"csv\")\n",
      "     |  mVar2 = load(\" \", format=\"csv\")\n",
      "     |  mVar3 = mVar2 + mVar1\n",
      "     |  mVar4 = mVar1 * mVar3\n",
      "     |  mVar5 = 1.0 - mVar4\n",
      "     |  save(mVar5, \" \")\n",
      "     |  >>> m2.eval()\n",
      "     |  >>> m2\n",
      "     |  # This matrix (mVar4) is backed by NumPy array. To fetch the NumPy array, invoke toNumPy() method.\n",
      "     |  >>> m4\n",
      "     |  # This matrix (mVar5) is backed by below given PyDML script (which is not yet evaluated). To fetch the data of this matrix, invoke toNumPy() or toDF() or toPandas() methods.\n",
      "     |  mVar4 = load(\" \", format=\"csv\")\n",
      "     |  mVar5 = 1.0 - mVar4\n",
      "     |  save(mVar5, \" \")\n",
      "     |  >>> m4.sum(axis=1).toNumPy()\n",
      "     |  array([[-60.],\n",
      "     |         [-60.],\n",
      "     |         [-60.]])\n",
      "     |  \n",
      "     |  Design Decisions:\n",
      "     |  \n",
      "     |  1. Until eval() method is invoked, we create an AST (not exposed to the user) that consist of unevaluated operations and data required by those operations.\n",
      "     |     As an anology, a spark user can treat eval() method similar to calling RDD.persist() followed by RDD.count().\n",
      "     |  2. The AST consist of two kinds of nodes: either of type matrix or of type DMLOp.\n",
      "     |     Both these classes expose _visit method, that helps in traversing the AST in DFS manner.\n",
      "     |  3. A matrix object can either be evaluated or not.\n",
      "     |     If evaluated, the attribute 'data' is set to one of the supported types (for example: NumPy array or DataFrame). In this case, the attribute 'op' is set to None.\n",
      "     |     If not evaluated, the attribute 'op' which refers to one of the intermediate node of AST and if of type DMLOp.  In this case, the attribute 'data' is set to None.\n",
      "     |  4. DMLOp has an attribute 'inputs' which contains list of matrix objects or DMLOp.\n",
      "     |  5. To simplify the traversal, every matrix object is considered immutable and an matrix operations creates a new matrix object.\n",
      "     |     As an example: \n",
      "     |     `m1 = sml.matrix(np.ones((3,3)))` creates a matrix object backed by 'data=(np.ones((3,3))'.\n",
      "     |     `m1 = m1 * 2` will create a new matrix object which is now backed by 'op=DMLOp( ... )' whose input is earlier created matrix object.\n",
      "     |  6. Left indexing (implemented in __setitem__ method) is a special case, where Python expects the existing object to be mutated.\n",
      "     |     To ensure the above property, we make deep copy of existing object and point any references to the left-indexed matrix to the newly created object.\n",
      "     |     Then the left-indexed matrix is set to be backed by DMLOp consisting of following pydml:\n",
      "     |     left-indexed-matrix = new-deep-copied-matrix\n",
      "     |     left-indexed-matrix[index] = value\n",
      "     |  7. Please use m.print_ast() and/or  type `m` for debugging. Here is a sample session:\n",
      "     |  \n",
      "     |     >>> npm = np.ones((3,3))\n",
      "     |     >>> m1 = sml.matrix(npm + 3)\n",
      "     |     >>> m2 = sml.matrix(npm + 5)\n",
      "     |     >>> m3 = m1 + m2\n",
      "     |     >>> m3\n",
      "     |     mVar2 = load(\" \", format=\"csv\")\n",
      "     |     mVar1 = load(\" \", format=\"csv\")\n",
      "     |     mVar3 = mVar1 + mVar2\n",
      "     |     save(mVar3, \" \")\n",
      "     |     >>> m3.print_ast()\n",
      "     |     - [mVar3] (op).\n",
      "     |       - [mVar1] (data).\n",
      "     |       - [mVar2] (data).\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __and__(self, other)\n",
      "     |      # TODO: Cast the output back into scalar and return boolean results\n",
      "     |  \n",
      "     |  __array__(self, dtype=<class 'numpy.float64'>)\n",
      "     |      As per NumPy from Python,\n",
      "     |      This method is called to obtain an ndarray object when needed. You should always guarantee this returns an actual ndarray object.\n",
      "     |      \n",
      "     |      Using this method, you get back a ndarray object, and subsequent operations on the returned ndarray object will be singlenode.\n",
      "     |  \n",
      "     |  __div__(self, other)\n",
      "     |      Performs division (Python 2 way).\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |      Implements evaluation of right indexing operations such as m[1,1], m[0:1,], m[:, 0:1]\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, data, op=None)\n",
      "     |      Constructs a lazy matrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data: NumPy ndarray, Pandas DataFrame, scipy sparse matrix or PySpark DataFrame. (data cannot be None for external users, 'data=None' is used internally for lazy evaluation).\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __matmul__(self, other)\n",
      "     |      Performs matrix multiplication (infix operator: @). See PEP 465)\n",
      "     |  \n",
      "     |  __mod__(self, other)\n",
      "     |  \n",
      "     |  __mul__(self, other)\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __numpy_ufunc__(self, func, method, pos, inputs, **kwargs)\n",
      "     |      This function enables systemml matrix to be compatible with NumPy's ufuncs.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func:  ufunc object that was called.\n",
      "     |      method: string indicating which Ufunc method was called (one of \"__call__\", \"reduce\", \"reduceat\", \"accumulate\", \"outer\", \"inner\").\n",
      "     |      pos: index of self in inputs.\n",
      "     |      inputs:  tuple of the input arguments to the ufunc\n",
      "     |      kwargs: dictionary containing the optional input arguments of the ufunc.\n",
      "     |  \n",
      "     |  __or__(self, other)\n",
      "     |  \n",
      "     |  __pow__(self, other)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      This function helps to debug matrix class and also examine the generated PyDML script\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmod__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(self, other)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__(self, other)\n",
      "     |      Performs division (Python 3 way).\n",
      "     |  \n",
      "     |  __setitem__(self, index, value)\n",
      "     |      Implements evaluation of left indexing operations such as m[1,1]=2\n",
      "     |  \n",
      "     |  __sub__(self, other)\n",
      "     |  \n",
      "     |  __truediv__(self, other)\n",
      "     |      Performs division (Python 3 way).\n",
      "     |  \n",
      "     |  abs(self)\n",
      "     |  \n",
      "     |  acos(self)\n",
      "     |  \n",
      "     |  arccos(self)\n",
      "     |  \n",
      "     |  arcsin(self)\n",
      "     |  \n",
      "     |  arctan(self)\n",
      "     |  \n",
      "     |  argmax(self, axis=None)\n",
      "     |      Returns the indices of the maximum values along an axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional (only axis=1, i.e. rowIndexMax is supported in this version)\n",
      "     |  \n",
      "     |  argmin(self, axis=None)\n",
      "     |      Returns the indices of the minimum values along an axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional  (only axis=1, i.e. rowIndexMax is supported in this version)\n",
      "     |  \n",
      "     |  asfptype(self)\n",
      "     |  \n",
      "     |  asin(self)\n",
      "     |  \n",
      "     |  astype(self, t)\n",
      "     |  \n",
      "     |  atan(self)\n",
      "     |  \n",
      "     |  ceil(self)\n",
      "     |  \n",
      "     |  ceiling(self)\n",
      "     |  \n",
      "     |  cos(self)\n",
      "     |  \n",
      "     |  cosh(self)\n",
      "     |  \n",
      "     |  cumsum(self, axis=None)\n",
      "     |      Returns the indices of the maximum values along an axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional (only axis=0, i.e. cumsum along the rows is supported in this version)\n",
      "     |  \n",
      "     |  deg2rad(self)\n",
      "     |      Convert angles from degrees to radians.\n",
      "     |  \n",
      "     |  dot(self, other)\n",
      "     |      Numpy way of performing matrix multiplication\n",
      "     |  \n",
      "     |  eval(self)\n",
      "     |      This is a convenience function that calls the global eval method\n",
      "     |  \n",
      "     |  exp(self)\n",
      "     |  \n",
      "     |  exp2(self)\n",
      "     |  \n",
      "     |  expm1(self)\n",
      "     |  \n",
      "     |  floor(self)\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |  \n",
      "     |  hstack(self, other)\n",
      "     |      Stack matrices horizontally (column wise). Invokes cbind internally.\n",
      "     |  \n",
      "     |  ldexp(self, other)\n",
      "     |  \n",
      "     |  log(self, y=None)\n",
      "     |  \n",
      "     |  log10(self)\n",
      "     |  \n",
      "     |  log1p(self)\n",
      "     |  \n",
      "     |  log2(self)\n",
      "     |  \n",
      "     |  logaddexp(self, other)\n",
      "     |  \n",
      "     |  logaddexp2(self, other)\n",
      "     |  \n",
      "     |  logical_not(self)\n",
      "     |  \n",
      "     |  max(self, other=None, axis=None)\n",
      "     |      Compute the maximum value along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other: matrix or numpy array (& other supported types) or scalar\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  mean(self, axis=None)\n",
      "     |      Compute the arithmetic mean along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  min(self, other=None, axis=None)\n",
      "     |      Compute the minimum value along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other: matrix or numpy array (& other supported types) or scalar\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  mod(self, other)\n",
      "     |  \n",
      "     |  moment(self, moment=1, axis=None)\n",
      "     |      Calculates the nth moment about the mean\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      moment : int\n",
      "     |          can be 1, 2, 3 or 4\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  negative(self)\n",
      "     |  \n",
      "     |  ones_like(self)\n",
      "     |  \n",
      "     |  print_ast(self)\n",
      "     |      Please use m.print_ast() and/or  type `m` for debugging. Here is a sample session:\n",
      "     |      \n",
      "     |      >>> npm = np.ones((3,3))\n",
      "     |      >>> m1 = sml.matrix(npm + 3)\n",
      "     |      >>> m2 = sml.matrix(npm + 5)\n",
      "     |      >>> m3 = m1 + m2\n",
      "     |      >>> m3\n",
      "     |      mVar2 = load(\" \", format=\"csv\")\n",
      "     |      mVar1 = load(\" \", format=\"csv\")\n",
      "     |      mVar3 = mVar1 + mVar2\n",
      "     |      save(mVar3, \" \")\n",
      "     |      >>> m3.print_ast()\n",
      "     |      - [mVar3] (op).\n",
      "     |        - [mVar1] (data).\n",
      "     |        - [mVar2] (data).\n",
      "     |  \n",
      "     |  prod(self)\n",
      "     |      Return the product of all cells in matrix\n",
      "     |  \n",
      "     |  rad2deg(self)\n",
      "     |      Convert angles from radians to degrees.\n",
      "     |  \n",
      "     |  reciprocal(self)\n",
      "     |  \n",
      "     |  remainder(self, other)\n",
      "     |  \n",
      "     |  remove_empty(self, axis=None)\n",
      "     |      Removes all empty rows or columns from the input matrix target X according to specified axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int (0 or 1)\n",
      "     |  \n",
      "     |  replace(self, pattern=None, replacement=None)\n",
      "     |      Removes all empty rows or columns from the input matrix target X according to specified axis.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      pattern : float or int\n",
      "     |      replacement : float or int\n",
      "     |  \n",
      "     |  round(self)\n",
      "     |  \n",
      "     |  save(self, file, format='csv')\n",
      "     |      Allows user to save a matrix to filesystem\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      file: filepath\n",
      "     |      format: can be csv, text or binary or mm\n",
      "     |  \n",
      "     |  sd(self, axis=None)\n",
      "     |      Compute the standard deviation along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |  \n",
      "     |  sign(self)\n",
      "     |  \n",
      "     |  sin(self)\n",
      "     |  \n",
      "     |  sinh(self)\n",
      "     |  \n",
      "     |  sqrt(self)\n",
      "     |  \n",
      "     |  square(self)\n",
      "     |  \n",
      "     |  sum(self, axis=None)\n",
      "     |      Compute the sum along the specified axis\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  tan(self)\n",
      "     |  \n",
      "     |  tanh(self)\n",
      "     |  \n",
      "     |  toDF(self)\n",
      "     |      This is a convenience function that calls the global eval method and then converts the matrix object into DataFrame.\n",
      "     |  \n",
      "     |  toNumPy(self)\n",
      "     |      This is a convenience function that calls the global eval method and then converts the matrix object into NumPy array.\n",
      "     |  \n",
      "     |  toPandas(self)\n",
      "     |      This is a convenience function that calls the global eval method and then converts the matrix object into Pandas DataFrame.\n",
      "     |  \n",
      "     |  trace(self)\n",
      "     |      Return the sum of the cells of the main diagonal square matrix\n",
      "     |  \n",
      "     |  transpose(self)\n",
      "     |      Transposes the matrix.\n",
      "     |  \n",
      "     |  var(self, axis=None)\n",
      "     |      Compute the variance along the specified axis.\n",
      "     |      We assume that delta degree of freedom is 1 (unlike NumPy which assumes ddof=0).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      axis : int, optional\n",
      "     |  \n",
      "     |  vstack(self, other)\n",
      "     |      Stack matrices vertically (row wise). Invokes rbind internally.\n",
      "     |  \n",
      "     |  zeros_like(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  THROW_ARRAY_CONVERSION_ERROR = False\n",
      "     |  \n",
      "     |  __array_priority__ = 10.2\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  dml = []\n",
      "     |  \n",
      "     |  ml = None\n",
      "     |  \n",
      "     |  ndim = 2\n",
      "     |  \n",
      "     |  script = None\n",
      "     |  \n",
      "     |  systemmlVarID = 0\n",
      "     |  \n",
      "     |  visited = []\n",
      "\n",
      "FUNCTIONS\n",
      "    _java2py(sc, obj)\n",
      "        Convert Java object to Python.\n",
      "    \n",
      "    convertImageToNumPyArr(im, img_shape=None, add_rotated_images=False, add_mirrored_images=False, color_mode='RGB', mean=None)\n",
      "        # Example usage: convertImageToNumPyArr(im, img_shape=(3, 224, 224), add_rotated_images=True, add_mirrored_images=True)\n",
      "        # The above call returns a numpy array of shape (6, 50176) in NCHW format\n",
      "    \n",
      "    convertToLabeledDF(sparkSession, X, y=None)\n",
      "    \n",
      "    convertToMatrixBlock(sc, src, maxSizeBlockInMB=8)\n",
      "    \n",
      "    convertToNumPyArr(sc, mb)\n",
      "    \n",
      "    convertToPandasDF(X)\n",
      "    \n",
      "    convert_caffemodel(sc, deploy_file, caffemodel_file, output_dir, format='binary', is_caffe_installed=False)\n",
      "        Saves the weights and bias in the caffemodel file to output_dir in the specified format.\n",
      "        This method does not requires caffe to be installed.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sc: SparkContext\n",
      "            SparkContext\n",
      "        \n",
      "        deploy_file: string\n",
      "            Path to the input network file\n",
      "        \n",
      "        caffemodel_file: string\n",
      "            Path to the input caffemodel file\n",
      "        \n",
      "        output_dir: string\n",
      "            Path to the output directory\n",
      "        \n",
      "        format: string\n",
      "            Format of the weights and bias (can be binary, csv or text)\n",
      "        \n",
      "        is_caffe_installed: bool\n",
      "            True if caffe is installed\n",
      "    \n",
      "    convert_lmdb_to_jpeg(lmdb_img_file, output_dir)\n",
      "        Saves the images in the lmdb file as jpeg in the output_dir. This method requires caffe to be installed along with lmdb and cv2 package.\n",
      "        To install cv2 package, do `pip install opencv-python`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        lmdb_img_file: string\n",
      "            Path to the input lmdb file\n",
      "        \n",
      "        output_dir: string\n",
      "            Output directory for images (local filesystem)\n",
      "    \n",
      "    debug_array_conversion(throwError)\n",
      "    \n",
      "    dml(scriptString)\n",
      "        Create a dml script object based on a string.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scriptString: string\n",
      "            Can be a path to a dml script or a dml script itself.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    dmlFromFile(filePath)\n",
      "        Create a dml script object based on a file path.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filePath: string\n",
      "            Path to a dml script.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    dmlFromResource(resourcePath)\n",
      "        Create a dml script object based on a resource path.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        resourcePath: string\n",
      "            Path to a dml script on the classpath.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    dmlFromUrl(url)\n",
      "        Create a dml script object based on a url.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        url: string\n",
      "            URL to a dml script.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    eval(outputs, execute=True)\n",
      "        Executes the unevaluated DML script and computes the matrices specified by outputs.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        outputs: list of matrices or a matrix object\n",
      "        execute: specified whether to execute the unevaluated operation or just return the script.\n",
      "    \n",
      "    full(shape, fill_value)\n",
      "        Return a new array of given shape filled with fill_value.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape: tuple of length 2\n",
      "        fill_value: float or int\n",
      "    \n",
      "    getDatasetMean(dataset_name)\n",
      "        Parameters\n",
      "        ----------\n",
      "        dataset_name: Name of the dataset used to train model. This name is artificial name based on dataset used to train the model.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mean: Mean value of model if its defined in the list DATASET_MEAN else None.\n",
      "    \n",
      "    getHopDAG(ml, script, lines=None, conf=None, apply_rewrites=True, with_subgraph=False)\n",
      "        Compile a DML / PyDML script.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ml: MLContext instance\n",
      "            MLContext instance.\n",
      "            \n",
      "        script: Script instance\n",
      "            Script instance defined with the appropriate input and output variables.\n",
      "        \n",
      "        lines: list of integers\n",
      "            Optional: only display the hops that have begin and end line number equals to the given integers.\n",
      "        \n",
      "        conf: SparkConf instance\n",
      "            Optional spark configuration\n",
      "            \n",
      "        apply_rewrites: boolean\n",
      "            If True, perform static rewrites, perform intra-/inter-procedural analysis to propagate size information into functions and apply dynamic rewrites\n",
      "        \n",
      "        with_subgraph: boolean\n",
      "            If False, the dot graph will be created without subgraphs for statement blocks. \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        hopDAG: string\n",
      "            hop DAG in dot format\n",
      "    \n",
      "    getNumCols(numPyArr)\n",
      "    \n",
      "    load(file, format='csv')\n",
      "        Allows user to load a matrix from filesystem\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        file: filepath\n",
      "        format: can be csv, text or binary or mm\n",
      "    \n",
      "    pydml(scriptString)\n",
      "        Create a pydml script object based on a string.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scriptString: string\n",
      "            Can be a path to a pydml script or a pydml script itself.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    pydmlFromFile(filePath)\n",
      "        Create a pydml script object based on a file path.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        filePath: string\n",
      "            Path to a pydml script.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    pydmlFromResource(resourcePath)\n",
      "        Create a pydml script object based on a resource path.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        resourcePath: string\n",
      "            Path to a pydml script on the classpath.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    pydmlFromUrl(url)\n",
      "        Create a pydml script object based on a url.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        url: string\n",
      "            URL to a pydml script.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        script: Script instance\n",
      "            Instance of a script object.\n",
      "    \n",
      "    seq(start=None, stop=None, step=1)\n",
      "        Creates a single column vector with values starting from <start>, to <stop>, in increments of <step>.\n",
      "        Note: Unlike Numpy's arange which returns a row-vector, this returns a column vector.\n",
      "        Also, Unlike Numpy's arange which doesnot include stop, this method includes stop in the interval.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        start: int or float [Optional: default = 0]\n",
      "        stop: int or float\n",
      "        step : int float [Optional: default = 1]\n",
      "    \n",
      "    setSparkContext(sc)\n",
      "        Before using the matrix, the user needs to invoke this function if SparkContext is not previously created in the session.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sc: SparkContext\n",
      "            SparkContext\n",
      "    \n",
      "    set_lazy(isLazy)\n",
      "        This method allows users to set whether the matrix operations should be executed in lazy manner.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        isLazy: True if matrix operations should be evaluated in lazy manner.\n",
      "    \n",
      "    solve(A, b)\n",
      "        Computes the least squares solution for system of linear equations A %*% x = b\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn import datasets\n",
      "        >>> import SystemML as sml\n",
      "        >>> from pyspark.sql import SparkSession\n",
      "        >>> diabetes = datasets.load_diabetes()\n",
      "        >>> diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
      "        >>> X_train = diabetes_X[:-20]\n",
      "        >>> X_test = diabetes_X[-20:]\n",
      "        >>> y_train = diabetes.target[:-20]\n",
      "        >>> y_test = diabetes.target[-20:]\n",
      "        >>> sml.setSparkContext(sc)\n",
      "        >>> X = sml.matrix(X_train)\n",
      "        >>> y = sml.matrix(y_train)\n",
      "        >>> A = X.transpose().dot(X)\n",
      "        >>> b = X.transpose().dot(y)\n",
      "        >>> beta = sml.solve(A, b).toNumPy()\n",
      "        >>> y_predicted = X_test.dot(beta)\n",
      "        >>> print('Residual sum of squares: %.2f' % np.mean((y_predicted - y_test) ** 2))\n",
      "        Residual sum of squares: 25282.12\n",
      "\n",
      "DATA\n",
      "    SUPPORTED_TYPES = (<class 'numpy.ndarray'>, <class 'pandas.core.frame....\n",
      "    __all__ = ['MLResults', 'MLContext', 'Script', 'Matrix', 'dml', 'pydml...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\ming\\appdata\\roaming\\python\\python36\\site-packages\\systemml\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(systemml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "# findspark.find()\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "sc = SparkContext(\"local[2]\", \"MarketStream\") # 2 threads, app name \n",
    "\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(systemml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SystemML API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from systemml import MLContext, dml\n",
    "# Create a MLContext object\n",
    "ml = MLContext(sc)\n",
    "# And print the information of SystemML version\n",
    "print(ml.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DML script for a Hello World' example and execute it using MLContext\n",
    "script = dml(\"\"\" \n",
    "print('Hello World'); \n",
    "\"\"\")\n",
    "ml.execute(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's modify the above script to get the Hello World string\n",
    "script = dml(\"\"\" \n",
    "s = 'Hello World' \n",
    "\"\"\").output(\"s\")\n",
    "\n",
    "hello_world_str = ml.execute(script).get(\"s\")\n",
    "\n",
    "print(hello_world_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import numpy, sklearn, and define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "plt.switch_backend('agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SystemML script to generate a random matrix, perform matrix multiplication, and compute the sum of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "    X = rand(rows=$nr, cols=1000, sparsity=0.5)\n",
    "    A = t(X) %*% X\n",
    "    s = sum(A)\n",
    "\"\"\"\n",
    "prog = dml(script).input('$nr', 1e6).output('s')\n",
    "s = ml.execute(prog).get('s')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load diabetes dataset from scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "diabetes_y_train = np.matrix(diabetes.target[:-20]).T\n",
    "diabetes_y_test = np.matrix(diabetes.target[-20:]).T\n",
    "\n",
    "# plt.scatter(diabetes_X_train, diabetes_y_train,  color='black')\n",
    "# plt.scatter(diabetes_X_test, diabetes_y_test,  color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Implement three different algorithms to train linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm 1: Linear Regression - Direct Solve (no regularization) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminaries\n",
    "\n",
    "1. The builtin function `solve(A, b)` computes the least squares solution for system of linear equations \n",
    "$$ Ax = b $$\n",
    "for the vector x such that $$ || \\; Ax \\; – \\; b \\;|| $$ is minimized. It is important to note that this function can operate only on small-to-medium sized input matrix that can fit in the driver memory. See the [DML language reference](http://apache.github.io/systemml/dml-language-reference.html) for more details.\n",
    "\n",
    "2. Linear regression model assumes that relationship between input explanatory (feature) variables X and numerical response variable y is linear. The goal is to estimate regression coefficient w (and residual variable) such that \n",
    "\n",
    "$$ y = \\text{Normal}(Xw, \\sigma^2) $$\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\text{Cost function, } J(w) &= \\dfrac{1}{2} (Xw - y)^2\n",
    "\\end{align*}$$\n",
    "\n",
    "Differentiating with respect to w,\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "dw &= \\dfrac{\\partial}{\\partial w} \\dfrac{1}{2} (Xw - y)^2 \\\\\n",
    "&= \\dfrac{1}{2} 2 X^T (Xw - y) \\\\\n",
    "&= (X^TX)w - X^Ty \n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "#### Setting the gradient\n",
    "To find minima, we set the derivative with respect to w to zero, \n",
    "$$\\begin{align*}\n",
    "(X^T X)w - (X^T y) &= 0 \\\\ \n",
    "w &= (X^T X)^{-1}(X^T y) \\\\\n",
    "\\text{Let } \\; A &= X^T X \\\\\n",
    "\\text{and } \\; b &= X^T y \\\\\n",
    "\\text{Therefore,} \\; w &= solve(A, b)\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "    # add constant feature to X to model intercept\n",
    "    ones = matrix(1, rows=nrow(X), cols=1)\n",
    "    X = cbind(X, ones)\n",
    "    A = t(X) %*% X\n",
    "    b = t(X) %*% y\n",
    "    w = solve(A, b)\n",
    "    bias = as.scalar(w[nrow(w),1])\n",
    "    w = w[1:nrow(w)-1,]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prog = dml(script).input(X=diabetes_X_train, y=diabetes_y_train).output('w', 'bias')\n",
    "w, bias = ml.execute(prog).get('w','bias')\n",
    "w = w.toNumPy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(diabetes_X_train, diabetes_y_train,  color='black')\n",
    "# plt.scatter(diabetes_X_test, diabetes_y_test,  color='red')\n",
    "\n",
    "# plt.plot(diabetes_X_test, (w*diabetes_X_test)+bias, color='blue', linestyle ='dotted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm 2: Linear Regression - Batch Gradient Descent (no regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm\n",
    "`Step 1: Start with an initial point \n",
    "while(not converged) { \n",
    "  Step 2: Compute gradient dw. \n",
    "  Step 3: Compute stepsize alpha.     \n",
    "  Step 4: Update: w_new = w_old - alpha*dw \n",
    "}`\n",
    "\n",
    "![Gradient Descent](http://blog.datumbox.com/wp-content/uploads/2013/10/gradient-descent.png)\n",
    "\n",
    "#### Gradient formula\n",
    "\n",
    "$$ dw = r = (X^T X)w - (X^T y) $$\n",
    "\n",
    "#### Step size formula\n",
    "\n",
    "We perform a line search to choose the step size `alpha` to minimize the cost function J(w). From basic calculus, `alpha` minimizes the function J(w) when the directional derivative with respect to `alpha` is zero. \n",
    "\n",
    "$$ alpha = \\dfrac{r^T r}{ r^T X^T X r } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "    # add constant feature to X to model intercepts\n",
    "    ones = matrix(1, rows=nrow(X), cols=1)\n",
    "    X = cbind(X, ones)\n",
    "    max_iter = 100\n",
    "    w = matrix(0, rows=ncol(X), cols=1)\n",
    "    for(i in 1:max_iter){\n",
    "        XtX = t(X) %*% X\n",
    "        dw = XtX %*%w - t(X) %*% y\n",
    "        alpha = (t(dw) %*% dw) / (t(dw) %*% XtX %*% dw)\n",
    "        w = w - dw*alpha\n",
    "    }\n",
    "    bias = as.scalar(w[nrow(w),1])\n",
    "    w = w[1:nrow(w)-1,]    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = dml(script).input(X=diabetes_X_train, y=diabetes_y_train).output('w').output('bias')\n",
    "w, bias = ml.execute(prog).get('w', 'bias')\n",
    "w = w.toNumPy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(diabetes_X_train, diabetes_y_train,  color='black')\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='red')\n",
    "\n",
    "plt.plot(diabetes_X_test, (w*diabetes_X_test)+bias, color='red', linestyle ='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 3: Linear Regression - Conjugate Gradient (no regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with gradient descent: Takes very similar directions many times\n",
    "\n",
    "Solution: Enforce conjugacy\n",
    "\n",
    "`Step 1: Start with an initial point \n",
    "while(not converged) {\n",
    "   Step 2: Compute gradient dw.\n",
    "   Step 3: Compute stepsize alpha.\n",
    "   Step 4: Compute next direction p by enforcing conjugacy with previous direction.\n",
    "   Step 4: Update: w_new = w_old + alpha*p\n",
    "}`\n",
    "\n",
    "![Gradient Descent vs Conjugate Gradient](http://i.stack.imgur.com/zh1HH.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = \"\"\"\n",
    "    # add constant feature to X to model intercepts\n",
    "    X = cbind(X, matrix(1, rows=nrow(X), cols=1))\n",
    "    m = ncol(X); i = 1; \n",
    "    max_iter = 20;\n",
    "    w = matrix (0, rows = m, cols = 1); # initialize weights to 0\n",
    "    dw = - t(X) %*% y; p = - dw;        # dw = (X'X)w - (X'y)\n",
    "    norm_r2 = sum (dw ^ 2); \n",
    "    for(i in 1:max_iter) {\n",
    "        q = t(X) %*% (X %*% p)\n",
    "        alpha = norm_r2 / sum (p * q);  # Minimizes f(w - alpha*r)\n",
    "        w = w + alpha * p;              # update weights\n",
    "        dw = dw + alpha * q;           \n",
    "        old_norm_r2 = norm_r2; norm_r2 = sum (dw ^ 2);\n",
    "        p = -dw + (norm_r2 / old_norm_r2) * p; # next direction - conjugacy to previous direction\n",
    "        i = i + 1;\n",
    "    }\n",
    "    bias = as.scalar(w[nrow(w),1])\n",
    "    w = w[1:nrow(w)-1,]    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = dml(script).input(X=diabetes_X_train, y=diabetes_y_train).output('w').output('bias')\n",
    "w, bias = ml.execute(prog).get('w','bias')\n",
    "w = w.toNumPy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(diabetes_X_train, diabetes_y_train,  color='black')\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='red')\n",
    "\n",
    "plt.plot(diabetes_X_test, (w*diabetes_X_test)+bias, color='red', linestyle ='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Invoke existing SystemML algorithm script LinearRegDS.dml using MLContext API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemml import dmlFromResource\n",
    "prog = dmlFromResource('scripts/algorithms/LinearRegDS.dml').input(X=diabetes_X_train, y=diabetes_y_train).input('$icpt',1.0).output('beta_out')\n",
    "w = ml.execute(prog).get('beta_out')\n",
    "w = w.toNumPy()\n",
    "bias=w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemml import dmlFromResource\n",
    "prog = dmlFromResource('scripts/algorithms/LinearRegDS.dml').input(X=diabetes_X_train, y=diabetes_y_train).input('$icpt',1.0).output('beta_out')\n",
    "w = ml.execute(prog).get('beta_out')\n",
    "w = w.toNumPy()\n",
    "bias=w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(diabetes_X_train, diabetes_y_train,  color='black')\n",
    "# plt.scatter(diabetes_X_test, diabetes_y_test,  color='red')\n",
    "\n",
    "# plt.plot(diabetes_X_test, (w[0]*diabetes_X_test)+bias, color='red', linestyle ='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Invoke existing SystemML algorithm using scikit-learn/SparkML pipeline like API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*mllearn* API allows a Python programmer to invoke SystemML's algorithms using scikit-learn like API as well as Spark's MLPipeline API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SQLContext\n",
    "\n",
    "from systemml.mllearn import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from systemml.mllearn import LinearRegression\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression(sqlCtx)\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regr.predict(diabetes_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the trained model to perform prediction\n",
    "%matplotlib inline\n",
    "plt.scatter(diabetes_X_train, diabetes_y_train,  color='black')\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='red')\n",
    "\n",
    "plt.plot(diabetes_X_test, predictions, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Install OpenBLAS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget https://github.com/xianyi/OpenBLAS/archive/v0.2.20.tar.gz\n",
    "!tar -xzf v0.2.20.tar.gz\n",
    "!cd OpenBLAS-0.2.20/ && make clean\n",
    "!cd OpenBLAS-0.2.20/ && make USE_OPENMP=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5: Invoking a Keras model with SystemML\n",
    "\n",
    "See [SystemML's deep learning documentation](http://apache.github.io/systemml/deep-learning) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systemml.mllearn import Keras2DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import mnist_data\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "# Download the MNIST dataset\n",
    "X, y = mnist_data()\n",
    "X, y = shuffle(X, y)\n",
    "# Split the data into training and test\n",
    "n_samples = len(X)\n",
    "X_train = X[:int(.9 * n_samples)]\n",
    "y_train = y[:int(.9 * n_samples)]\n",
    "X_test = X[int(.9 * n_samples):]\n",
    "y_test = y[int(.9 * n_samples):]\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout,Flatten\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "input_shape = (1,28,28) if K.image_data_format() == 'channels_first' else (28,28, 1)\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape, padding='same'))\n",
    "keras_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "keras_model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "keras_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "keras_model.add(Flatten())\n",
    "keras_model.add(Dense(512, activation='relu'))\n",
    "keras_model.add(Dropout(0.5))\n",
    "keras_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Scale the input features\n",
    "scale = 0.00390625\n",
    "X_train = X_train*scale\n",
    "X_test = X_test*scale\n",
    "\n",
    "from systemml.mllearn import Keras2DML\n",
    "sysml_model = Keras2DML(spark, keras_model, input_shape=(1,28,28), weights='weights_dir')\n",
    "sysml_model.setConfigProperty('sysml.native.blas', 'openblas')\n",
    "sysml_model.setConfigProperty('sysml.native.blas.directory', os.path.join(os.getcwd(),'OpenBLAS-0.2.20/'))\n",
    "# sysml_model.setGPU(True).setForceGPU(True)\n",
    "sysml_model.summary()\n",
    "sysml_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
